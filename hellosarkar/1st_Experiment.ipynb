{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1483a38-4c7b-441c-b097-0b987778dec2",
   "metadata": {},
   "source": [
    "# GRIEVANCE SEGRIGATION "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fd7a9cf",
   "metadata": {},
   "source": [
    "Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8599d2-0461-4465-b38b-04fad90a03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth',None)   \n",
    "import collections\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c52d903-9f4c-4587-a439-b82a2386712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(\"FINAL.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a52e3ac3",
   "metadata": {},
   "source": [
    "Top Five Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a18d2d-f224-4ad6-bcb3-708ebb329fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>गुनासो वर्ग</th>\n",
       "      <th>गुनासो</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>लागु पदार्थ सम्बन्धी</td>\n",
       "      <td>धनुषा जील्ला वडा न‍ २३  जिरो माइल प्रहरी चौकी नजिक रहेका ८ वटा पसलहरुमा घरेलु मदीरा बक्री भैरहेको छ । उत कार्यमा  जिरो माइल प्रहरी चौकिका इन्चार्ज चन्दन शीह को मीलोमतो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>लागु पदार्थ सम्बन्धी</td>\n",
       "      <td>भारतिय नागरिकले लागु पदार्थ सेवन गरि जथाभावि बोल्ने गरेको</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>लागु पदार्थ सम्बन्धी</td>\n",
       "      <td>अन्तर्राष्ट्रिय सिमाना नजिकै हुने मदिरा को व्यापार  ले भारतीय नागरिक हरु को बाक्लो आवत जावत हुने गर्दछ र नशा मा मात्तिएर उनिहरु दैनिक जसो  स्थानिय को घर अगाडि जथाभावी बोल्ने झगडा गर्ने जस्ता घटना नौला होइनन्</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>लागु पदार्थ सम्बन्धी</td>\n",
       "      <td>तामाङ्ग गुम्बा नजिक  राति राति  मादकपदार्थको बिक्रि वितरण गर्ने र मादकपदार्थ  खाई होहल्ला गरेको कारणले  स्थानिय बासिन्दालाई समस्या परेको</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>लागु पदार्थ सम्बन्धी</td>\n",
       "      <td>देशका विभिन्न ठाउहरूमा सुर्तिजन्य तथा मदिराजन्य पदार्थको खुलमखुल्ला विक्रि वितरण भैरहेकोले यसको नियमन गर्नुपर्ने देखियो भन्ने व्यहोराको गुनासो प्राप्त भएको</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             गुनासो वर्ग  \\\n",
       "0  लागु पदार्थ सम्बन्धी    \n",
       "1  लागु पदार्थ सम्बन्धी    \n",
       "2  लागु पदार्थ सम्बन्धी    \n",
       "3  लागु पदार्थ सम्बन्धी    \n",
       "4  लागु पदार्थ सम्बन्धी    \n",
       "\n",
       "                                                                                                                                                                                                            गुनासो  \n",
       "0                                          धनुषा जील्ला वडा न‍ २३  जिरो माइल प्रहरी चौकी नजिक रहेका ८ वटा पसलहरुमा घरेलु मदीरा बक्री भैरहेको छ । उत कार्यमा  जिरो माइल प्रहरी चौकिका इन्चार्ज चन्दन शीह को मीलोमतो  \n",
       "1                                                                                                                                                        भारतिय नागरिकले लागु पदार्थ सेवन गरि जथाभावि बोल्ने गरेको  \n",
       "2  अन्तर्राष्ट्रिय सिमाना नजिकै हुने मदिरा को व्यापार  ले भारतीय नागरिक हरु को बाक्लो आवत जावत हुने गर्दछ र नशा मा मात्तिएर उनिहरु दैनिक जसो  स्थानिय को घर अगाडि जथाभावी बोल्ने झगडा गर्ने जस्ता घटना नौला होइनन्  \n",
       "3                                                                         तामाङ्ग गुम्बा नजिक  राति राति  मादकपदार्थको बिक्रि वितरण गर्ने र मादकपदार्थ  खाई होहल्ला गरेको कारणले  स्थानिय बासिन्दालाई समस्या परेको  \n",
       "4                                                      देशका विभिन्न ठाउहरूमा सुर्तिजन्य तथा मदिराजन्य पदार्थको खुलमखुल्ला विक्रि वितरण भैरहेकोले यसको नियमन गर्नुपर्ने देखियो भन्ने व्यहोराको गुनासो प्राप्त भएको  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43818bc9",
   "metadata": {},
   "source": [
    "Naming of Class and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9063f57-6ebb-4693-8bcf-f6cc64dd9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=dataset['गुनासो']\n",
    "Y1=list(dataset['गुनासो वर्ग'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20cfb369-1c9c-4aa4-ba3a-1ca30216765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10335 entries, 0 to 10334\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   गुनासो वर्ग  10335 non-null  object\n",
      " 1   गुनासो       10335 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 161.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becfe22c-a076-4a27-9a9e-8774a4679eb1",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63980d-ea95-4785-a906-c99a72b342ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d21f71-9f92-497c-8251-ccb88cbe62b6",
   "metadata": {},
   "source": [
    "stopWords = set(nltk.corpus.stopwords.words('nepali'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7478484a-2a85-4d1b-ab16-6468241074a1",
   "metadata": {},
   "source": [
    "stopWords=set(stopwords.words('nepali'))\n",
    "X_data=[]\n",
    "for i in X:\n",
    "    गुनासो=' '.join([word for word in i.split() if word not in stopWords])\n",
    "    X_data.append(गुनासो.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac67a73-4ebb-466c-8794-f97564eca8a4",
   "metadata": {},
   "source": [
    "Stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb82110-efb8-4251-ac2a-a8321b136939",
   "metadata": {},
   "source": [
    "Stopwords=set(stopwords.words('english'))\n",
    "X_data=[]\n",
    "for i in X:\n",
    "    गुनासो=' '.join([word for word in i.split() if word not in Stopwords])\n",
    "    X_data.append(गुनासो.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec15ff39-9b1a-4f68-9573-af3acbbbb4c8",
   "metadata": {},
   "source": [
    "#removing all unnecessary expression\n",
    "import re\n",
    "def processText(गुनासो):\n",
    "    गुनासो = गुनासो.lower()\n",
    "    गुनासो = re.sub(r'((www.[^s]+)|(https?://[^s]+))',r'',गुनासो)\n",
    "    गुनासो = re.sub(r'[s]+', r'',गुनासो)\n",
    "    गुनासो = re.sub(r'#([^s]+)', r'', गुनासो)\n",
    "    गुनासो = re.sub(r'[.!:?\"\\।|,]', r'', गुनासो)\n",
    "    गुनासो = re.sub(r'[\\u0966-\\u096F]+',r'',गुनासो)\n",
    "    गुनासो = re.sub(r'[\\([{})\\]]',r'',गुनासो)\n",
    "    गुनासो = re.sub(r'[a-zA-Z0-9\\+\\-\\'\\\"\\%\\&\\$]',r'',गुनासो)\n",
    "    गुनासो = गुनासो.strip()\n",
    "    \n",
    "    return गुनासो"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b554917-1d71-483c-b642-5a027e060a1f",
   "metadata": {},
   "source": [
    "for i in range(len(dataset)):\n",
    "    dataset['गुनासो'][i] = processText(dataset['गुनासो'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ce603-65fd-4e4b-a5cf-7bc0dd10491a",
   "metadata": {},
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26144794-cf8e-4b81-b7df-d8f917dc415a",
   "metadata": {},
   "source": [
    "import collections\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0da8dc-cae2-4e7c-bbe6-f9de1aa9cc66",
   "metadata": {},
   "source": [
    "corpus_list =[]\n",
    "for i,t in enumerate(X_data):\n",
    "    wordArr = X_data[i].split(\" \")\n",
    "    for j, p in enumerate(wordArr):\n",
    "        corpus_list.append(wordArr[j])\n",
    "counter=collections.Counter(corpus_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d3f574-fcc0-42d0-93d8-f201db0a9778",
   "metadata": {},
   "source": [
    "least_common= [word for word, word_count in Counter(corpus_list).most_common()[:-50:-1]]\n",
    "for i,t in enumerate(X_data):\n",
    "    word = X_data[i].split(\" \")\n",
    "    X_data[i] = \" \".join(ele for ele in word if ele not in least_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce770fd7-38bd-4e4b-b22f-ac4401c73d01",
   "metadata": {},
   "source": [
    "count = 0;\n",
    "for i in X:\n",
    "    X_data[count] = processText(X_data[count])\n",
    "    count= count +1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e891a48",
   "metadata": {},
   "source": [
    "Nepali Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7785cbb3-9407-4259-b203-ff66f28853ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_nepali = ['यो','म','यी','त्यो','ती','प्रति','हरेक','प्रतेक','माननीय','अलिकति','थोरै','सबै','केहि','एक','दुई','तिन','प्रथम','रही','आज','द्रितीय','तृतीय','को','सब','कुन','जी','श्री','वैसा','कति','जो', 'जसरी', 'जुन', 'र', 'तथा', 'तर', 'आदि', 'किन्तु', 'इत्यादि', 'परन्तु', 'ले', 'बाट', 'लाई', 'ले', 'द्वारा', 'वारि', 'पारि', 'अघाडी', 'कुमारी', 'चित्रकार', 'राम', 'उन', 'उनका', 'उनकी', 'पर्दिप', 'उनको', 'उस', 'एक', 'एवं', 'एस', 'कई', 'कहा', 'का', 'काफ़ी', 'कि','की', 'कुल', 'के', 'को', 'कोई', 'घर', 'जब', 'जहाँ', 'जा', 'जो', 'तब','तिस', 'थिए','हरि','थे', 'होला','द्वारा', 'न','ने', 'पर','पूरा','पे', 'यदि', 'यहाँ', 'यही', 'या', 'वर्ग','संग','हो','जेसे','दवारा','यहां','जे', 'यहि','मोबि','अदि','छ','हेरीच्छ','जहां']\n",
    "#to_be_removed = stopwords_nepali "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a0669-9f39-406d-b5d4-a91520cdf059",
   "metadata": {},
   "source": [
    "for i in range(len(dataset)):\n",
    "    dataset['गुनासो'][i]=[ele for ele in dataset['गुनासो'][i] if ele not in (to_be_removed)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c57931a-73a0-4a05-bfe6-3e1654a5a968",
   "metadata": {},
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df31e3-4b3c-4fc9-91aa-3a8df3f6e971",
   "metadata": {},
   "source": [
    "for i,t in enumerate(X_data):\n",
    "    word = X_data[i].split(\" \")\n",
    "    X_data[i] = \" \".join(ele for ele in word if ele not in to_be_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453ee02-abd7-41a3-8e62-d25d2d34aff9",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019acbee-e241-43cb-981e-82a8f9b72932",
   "metadata": {},
   "source": [
    "### Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7026922b-bb38-4b40-841c-dd3334244d71",
   "metadata": {},
   "source": [
    "X1=dataset['गुनासो']\n",
    "Y1=list(dataset['गुनासो वर्ग'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c1a455-52ea-478e-8dac-e9601de68b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "276daef9",
   "metadata": {},
   "source": [
    "Train and Test dataset (70% training size and 30% testing size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2c38773-9797-4dd4-9402-d3911d61ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X1,Y1,test_size=0.30,random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "189b3e9b",
   "metadata": {},
   "source": [
    "Term frequency count by TFIDF(Term Frequency Inverse Document Frequency) (Repeated word count for ML analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a1ccea1-f26c-48b4-924f-287943d61620",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c54ef7e1-a553-4157-8945-dde4cb79c9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['अघ', 'अद', 'अल', 'आद', 'इत', 'उनक', 'एव', 'कत', 'कह', 'जसर', 'जह', 'तथ', 'दव', 'नन', 'परन', 'यद', 'यह', 'रक', 'रत', 'रथम', 'रह', 'वर', 'हर'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def tfidf_features(X_train, X_test):\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords_nepali)\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    return X_train_tfidf,X_test_tfidf,tfidf_vectorizer.vocabulary_\n",
    "X_train_tfidf,X_test_tfidf,vocabulary=tfidf_features(X_train,X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31628ed5",
   "metadata": {},
   "source": [
    "Sparse to Dense for Naive Bayes (Sparse matrix to dense matrix as sparse matrix contains zero values which is not read by Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc77c75-5ce5-4ee5-a741-1c6fbfeb4a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Sparse to Dense\n",
    "X_train_Vectorized_Dense = X_train_tfidf.todense()\n",
    "X_test_Vectorized_Dense = X_test_tfidf.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f0db9d-5ce9-491a-9e49-5507ab6e1fb3",
   "metadata": {},
   "source": [
    "### ML ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ffc362-e473-4fb1-bcbc-165fc2c968c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier,GradientBoostingClassifier,RandomForestClassifier,AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2764c7fa-348a-4a9a-b7e7-4e1a61d6ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdda97c4",
   "metadata": {},
   "source": [
    "Function for accuracy and F1 for Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e15b690e-41e0-412c-bbab-b2774793cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificationAlgorithm_dense(func, **kwargs):\n",
    "\n",
    "  def innerFunction():\n",
    "    model = func(**kwargs)\n",
    "    model.fit(X_train_Vectorized_Dense, Y_train)\n",
    "\n",
    "    Y_pred = model.predict(X_test_Vectorized_Dense)\n",
    "    \n",
    "    print(\"Confusion Matrix : \\n\",confusion_matrix(Y_test,Y_pred),\"\\n\")\n",
    "    print(\"Accuracy Score : \",accuracy_score(Y_test,Y_pred))\n",
    "    print(\"F1 Score : \",f1_score(Y_test,Y_pred,average='weighted'))\n",
    "\n",
    "  return innerFunction()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67fe48af",
   "metadata": {},
   "source": [
    "Function for accuracy and F1 for Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db9cb81c-047c-4e06-9705-3cdfdc50f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificationAlgorithm(func, **kwargs):\n",
    "\n",
    "  def innerFunction():\n",
    "    model = func(**kwargs)\n",
    "    model.fit(X_train_tfidf,Y_train)\n",
    "    \n",
    "    Y_pred= model.predict(X_test_tfidf)\n",
    "    \n",
    "    print (\"Confusion Matrix : \\n\", confusion_matrix(Y_test, Y_pred), \"\\n\")\n",
    "    print(\"Testing Accuracy is  :%s\" %(model.score(X_test_tfidf, Y_test)))\n",
    "    print (\"F1 Score : \" , f1_score(Y_test, Y_pred, average='weighted'))\n",
    "    \n",
    "  return innerFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570bceb1-c5b2-4b8d-a5f2-ac667ffbe1ab",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR MACHINE (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f82d32ba-6dea-41af-8360-8039738ac467",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[143   1  27   4   1   2  24   6   6  29  10]\n",
      " [  4   0   7   1   1   0   1   1   0   2   1]\n",
      " [ 27   1 249  10   3   3  42   8   3  37  21]\n",
      " [  5   0  14 157   3   1  15   4   3  13   4]\n",
      " [  6   0   8   2  39   1   7   1   0  10   2]\n",
      " [  2   0   4   0   0  24   2   3   3   3   2]\n",
      " [ 16   0  31  12   0   1 716   2   4 108   7]\n",
      " [  9   1  24   8   2   3  14  86   2  19   8]\n",
      " [  9   0   5   5   0   2  22   3 131  15   4]\n",
      " [ 25   0  47  10   5   0 179   5  10 262  22]\n",
      " [ 15   0  35   5   2   1  11   5   5  35 140]] \n",
      "\n",
      "Testing Accuracy is  :0.6278619800064495\n",
      "F1 Score :  0.6232087931773601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "ClassificationAlgorithm(LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "662557cf-63f2-4792-9e36-fa265b4941a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[111   0  41   1   0   0  52   0   0  46   2]\n",
      " [  1   0   9   1   0   0   2   0   0   3   2]\n",
      " [ 10   0 247   4   0   1  72   2   2  56  10]\n",
      " [  1   0  10 137   0   0  29   1   3  37   1]\n",
      " [  4   0  10   2  23   0  18   1   0  18   0]\n",
      " [  1   0  12   1   0  12   3   1   0   9   4]\n",
      " [  5   0  21   7   0   0 776   0   1  84   3]\n",
      " [  7   0  35   2   0   0  37  65   1  27   2]\n",
      " [  4   0   4   5   0   1  53   2 107  18   2]\n",
      " [ 11   0  40   5   0   0 218   0   3 278  10]\n",
      " [  8   0  38   5   0   0  38   0   1  51 113]] \n",
      "\n",
      "Testing Accuracy is  :0.6027088036117382\n",
      "F1 Score :  0.5926726933349344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "ClassificationAlgorithm(SVC,kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dd5e5a5-96cb-48f4-b471-2c7d8dedf8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[ 36   0  25   0   0   0 161   0   0  30   1]\n",
      " [  1   0   6   0   0   0   9   0   0   2   0]\n",
      " [  2   0 172   1   0   0 185   0   0  41   3]\n",
      " [  0   0   3  40   0   0 156   0   0  20   0]\n",
      " [  0   0   6   0   5   0  55   1   0   9   0]\n",
      " [  0   0   3   0   0   1  37   0   0   2   0]\n",
      " [  1   0   7   0   0   0 853   0   0  36   0]\n",
      " [  1   0  21   0   0   0 108  37   0   9   0]\n",
      " [  1   0   3   0   0   0 143   0  31  18   0]\n",
      " [  1   0  23   0   0   0 378   0   0 162   1]\n",
      " [  1   0  17   0   0   0 165   0   1  31  39]] \n",
      "\n",
      "Testing Accuracy is  :0.4437278297323444\n",
      "F1 Score :  0.38899729336661915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "ClassificationAlgorithm(SVC,kernel='poly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4fd579-9f35-48e5-a089-e63f5308639d",
   "metadata": {},
   "source": [
    "\n",
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eabbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "650f9e53-82c0-49e3-bba1-a870cb6cf9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Convert Sparse to Dense\n",
    "X_train_Vectorized_Dense = X_train_tfidf.todense()\n",
    "X_test_Vectorized_Dense = X_test_tfidf.todense()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc64c985",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63e1ad96-3fef-4b47-9fbb-4aebce57543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[ 76  20  44  11   6   6  15  16  17  25  17]\n",
      " [  4   2   4   0   1   0   0   2   0   3   2]\n",
      " [ 39  20 183  14  12  13  22  21  17  36  27]\n",
      " [ 13  29  25  77   8  11   5  12  11  16  12]\n",
      " [  1   3  27   2  18   4   4   4   1   9   3]\n",
      " [  2   5   3   2   3  18   0   4   0   1   5]\n",
      " [ 93  73  58  52  10  22 314  18  85 144  28]\n",
      " [ 11   3  34   0   6   3   8  74   7  19  11]\n",
      " [  8  12  28   5   4   2  23   2  87  19   6]\n",
      " [ 52  54  75  30  11  18  74  31  41 134  45]\n",
      " [ 19  13  40  11   6   6   7  10  15  31  96]] \n",
      "\n",
      "Accuracy Score :  0.34795227346017416\n",
      "F1 Score :  0.366232893403448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "ClassificationAlgorithm_dense(GaussianNB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cae9f42",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbeedcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationAlgorithm_dense(BernoulliNB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "999af279",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationAlgorithm_dense(MultinomialNB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb9c67ae",
   "metadata": {},
   "source": [
    "Complement Naive Bayes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationAlgorithm_dense(ComplementNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33091809-4bcd-4409-8144-5d6e366c1ebb",
   "metadata": {},
   "source": [
    "### Multi lingual bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fe4549b-c560-49c3-b421-75e62894866a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\MECE\\Thesis Work\\Research\\1st_Experiment.ipynb Cell 45\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/MECE/Thesis%20Work/Research/1st_Experiment.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msimpletransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclassification\u001b[39;00m \u001b[39mimport\u001b[39;00m ClassificationModel\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\simpletransformers\\classification\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msimpletransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclassification\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclassification_model\u001b[39;00m \u001b[39mimport\u001b[39;00m ClassificationModel\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msimpletransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclassification\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmulti_label_classification_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     MultiLabelClassificationModel,\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msimpletransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclassification\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmulti_modal_classification_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     MultiModalClassificationModel,\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\simpletransformers\\classification\\classification_model.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m mode, pearsonr\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspecial\u001b[39;00m \u001b[39mimport\u001b[39;00m softmax\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py:831\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    824\u001b[0m         __all__\u001b[39m.\u001b[39mappend(name)\n\u001b[0;32m    826\u001b[0m \u001b[39m################################################################################\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[39m# Import interface functions defined in Python\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[39m################################################################################\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \n\u001b[0;32m    830\u001b[0m \u001b[39m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[39;00m\n\u001b[1;32m--> 831\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \u001b[39m################################################################################\u001b[39;00m\n\u001b[0;32m    835\u001b[0m \u001b[39m# Remove unnecessary members\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[39m################################################################################\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[39mdel\u001b[39;00m _StorageBase\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\functional.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m _add_docstr\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mopt_einsum\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mopt_einsum\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_lowrank\u001b[39;00m \u001b[39mimport\u001b[39;00m svd_lowrank, pca_lowrank\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39moverrides\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n\u001b[0;32m     12\u001b[0m     handle_torch_function)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\__init__.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparameter\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     Parameter \u001b[39mas\u001b[39;00m Parameter,\n\u001b[0;32m      4\u001b[0m     UninitializedParameter \u001b[39mas\u001b[39;00m UninitializedParameter,\n\u001b[0;32m      5\u001b[0m     UninitializedBuffer \u001b[39mas\u001b[39;00m UninitializedBuffer,\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparallel\u001b[39;00m \u001b[39mimport\u001b[39;00m DataParallel \u001b[39mas\u001b[39;00m DataParallel\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m init\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m functional\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\parallel\\__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparallel_apply\u001b[39;00m \u001b[39mimport\u001b[39;00m parallel_apply\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mreplicate\u001b[39;00m \u001b[39mimport\u001b[39;00m replicate\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata_parallel\u001b[39;00m \u001b[39mimport\u001b[39;00m DataParallel, data_parallel\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mscatter_gather\u001b[39;00m \u001b[39mimport\u001b[39;00m scatter, gather\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\parallel\\replicate.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m comm\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m _get_device_index\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m OrderedDict\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "748af17e-cc9f-48e6-8f0e-0ceed0b5ab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'अर्थ सबन्धी', 'शान्ति सुरक्षा सम्बन्धी', 'स्वास्थ्यसँग सम्बन्धी', 'सूचना तथा संचार सम्बन्धी'}\n"
     ]
    }
   ],
   "source": [
    "print(set(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b978901a-be1b-40d2-b498-4d450804209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                           गुनासो  \\\n",
      "610                                                                                                                                                                    बिज्ञापन निकालेर राजस्ब लिएको महीनौ बितीसकदा पनि firm summit na vyeko र राजस्ब लीएर अहीले सम्म कुनैपनि परीक्षा मिति निकालेको छैन ।\\n राज्सब फ्रिता गरिपाउ या परिक्षा काे मिति पाउ भनि याे सानाे अनुराेध छ।   \n",
      "1458  दुवै NTC र NCELL को नेटवर्क ले राम्रो काम गर्दैन। 2g network full देखाउँछ तर कल लाग्दैन । balance धरी चेक हुँदैन। 3g 4g network १-२ line signal आउछ तर call र DATA राम्रो चल्दैन ।। नेट चलाउनु फरक फरक ठाउँ खोज्दै की बाटोतिर की खेत तिर जानुपर्छ। MAIN समस्या फोन गर्दा कसैलाई लाग्दैन। नेटवर्क को समस्या धरै xa हाम्रो एरिया मा । कृपया यसको समाधान गरिदिनु होला। धन्यवाद   \n",
      "2848                                                                                                                                                                                                                                                                                                                         It is comsoneeder.\\nOn disdaining me & slapped by me   \n",
      "1802                                                                                                                                                                                                                                                                       कोभिड १९ महामारीको कारण कोरोना सक्रमित व्यक्तीलाई अस्पतालमा शैया अभाव भएको भन्ने गुनासो प्राप्त भएको ।   \n",
      "2308                                                                                                                                                                                                                    बिधुतिय हाजिरी सुरु नगरे को, डाक्टरहरु समय अगावै कार्यालय छोडी आफ्नो निजि क्लिनिक मा जाने . कोरोना सके पनि बिधुतिय हाजिरी सुरु किन सुरु nagareko. धन्यबाद   \n",
      "\n",
      "      label  \n",
      "610       0  \n",
      "1458      2  \n",
      "2848      1  \n",
      "1802      3  \n",
      "2308      3  \n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "labeler = preprocessing.LabelEncoder()\n",
    "\n",
    "df3 = pd.DataFrame(X_train)\n",
    "df3['label'] = labeler.fit_transform(Y_train)\n",
    "print(df3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37a84799-ff8c-4b15-963a-645d5410143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/badalgami/opt/anaconda3/lib/python3.9/site-packages/simpletransformers/classification/classification_model.py:601: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52da51f4e9044d2db7c4364094ff7978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4d80c12ad849f0a14ae78e7b45b554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2d552485f043a38ff96024bfe6c7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f578a1445548c982f1a3361df3a3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a998ebb32045589d1cd9a2a6e4e6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel('bert', 'bert-base-multilingual-uncased', num_labels=4, use_cuda=False, args={\n",
    "    'reprocess_input_data': True,\n",
    "    'use_cached_eval_features': False,\n",
    "    'overwrite_output_dir': True,\n",
    "    'num_train_epochs': 3\n",
    "})\n",
    "model.train_model(df3)\n",
    "print(\"trained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78b6db6e-62ca-467e-8df7-c37736f12d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   गुनासो  \\\n",
      "1946                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     यस कान्ति बाल अस्पतालमा विगत  हप्तादेखि  जाँच सेवा बन्द रहेको छ  यस अस्पतालमा क्यान्सरका बच्चा हरु उपचाररत छन् जसको लागि  गरिरहनु पर्ने हुन्छ तर ल्याबको कर्मचारीहरुलाई सोध्दा रेजिन नभएकोले सेवा बन्द रहेको जानकारी हुन आयो  तसर्थ यो सेवा शीघ्र सञ्चालनको लागि व्यवस्था मिलाई दिनुहुन अनुरोध छ   \n",
      "666                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      "22    नेपाल राष्ट्र बैँकले निर्देशन जारी गरी लक्की ड्र  गोलाप्रथा चिठ्ठा उपहार योजना लगायतका कार्य नगर्न निर्देशन गरे पनी सबै ग्राहकलाई समान रुपमा ब्यबहार गर्न भने पनी  क्यास ब्याक योजना सञ्चालन गर्नु अगावै नेराबैँ भुक्तानी प्रणाली बिभागको स्विकृती लिनुपर्ने ब्यबस्था गरे पनी केही बैँकहरुले यसलाई अटेर गर्दै आएका छन्  प्रस्तुत सन्दर्भमा एनआईसी एसिया बैँकले गोलाप्रथा मार्फत / प्रथम तिनजनालाई गर्ने क्यास ब्याकको लागी राष्ट्र बैँक भुक्तानी प्रणाली बिभागको स्विकृती लिएको हो होईन तथा भुक्तानी प्रणाली बिभागले स्विकृती दिएको भए राष्ट्र बैँकको सबै ग्राहकलाई समान ब्यबहार गर्नुपर्ने निर्देशनको बर्खिलाप हुने गरी किन स्विकृती गरेको हो सो सम्बन्धमा रा बैँ बैँक सुपरिबेक्षण बिभाग तथा भुक्तनी प्रणाली बिभागको ध्यानाकर्षण गराई यस्ता अवान्छनिय गतिविधिमा रोक लगाउन अनुरोध छ   \n",
      "104                                                                                                                                                                                                                                              पिडित कृष्ण सोमै लाइ मोहम्मद मुसलमान नाम गरेको ब्याक्ति ले बाउन्स चेक दिएर दुख मात्र दिई राखेको छ  चेक भएर पनी पैसा नसकेकोले चैत्र मैहिना मा चेक बाउंस गर्छु भन्दा कोविड  को कारण बैंक बन्द भएर बाउन्स गर्न नसकिएको र अहिले कल गर्दा कल नउठाउने भेट्न जादा उक्त व्यक्ति सँग भेट नहुने गरेको  मैले लिनु पर्ने कुल रकम  छ र उहाँले मलाई  को  वटा चेक दिनु भयो उक्त चेक आफ्नो छोराको नाम मा छ नसाटिय पछि फेरि रु  को चेक आफ्नै नाममा दिएको त्यो पनि नसाटिएको हुनाले उक्त व्यक्तिलाई कारवाही गरी पैसा फर्ता पाउँ भन्ने गुनासो प्राप्त भएको छ   \n",
      "702                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      "\n",
      "      label  \n",
      "1946      3  \n",
      "666       0  \n",
      "22        0  \n",
      "104       0  \n",
      "702       0  \n"
     ]
    }
   ],
   "source": [
    "eval_frame = pd.DataFrame(X_test)\n",
    "eval_frame['label'] = labeler.fit_transform(Y_test)\n",
    "print(eval_frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0d7bf44-c4f4-4415-bbf6-5b3255a9366f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725\n"
     ]
    }
   ],
   "source": [
    "print(len(eval_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd7e640e-67a2-4ef8-ba51-6ed9b59e590b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/badalgami/opt/anaconda3/lib/python3.9/site-packages/simpletransformers/classification/classification_model.py:1442: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40b651ad0714a7a8aa7bc33b232b33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3454144e15414a80a645fd13b5b697d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong predictions (by input I think?):\n",
      "{0: 107, 1: 64, 3: 50, 2: 81}\n"
     ]
    }
   ],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(eval_frame)\n",
    "bads = {}\n",
    "for pred in wrong_predictions:\n",
    "    if pred.label in bads:\n",
    "        bads[pred.label] += 1\n",
    "    else:\n",
    "        bads[pred.label] = 1\n",
    "print(\"wrong predictions (by input I think?):\")\n",
    "print(bads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53101f55-374f-44dc-a2e2-adea66a812cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.34482758620689"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-(107+64+50+81)/725)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942b764-aad0-42d7-9e26-71f00ed2437b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
